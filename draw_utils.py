from matplotlib import pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix
from torch import Tensor
import cv2


def plot_confusion_matrix(y_true, y_pred, classes, sub_name):
    y_true, y_pred = Tensor.cpu(y_true), Tensor.cpu(y_pred)
    plt.rc('font', size='8')  # 设置字体样式、大小
    cm = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)
    # 按行进行归一化
    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    # ax.figure.colorbar(im, ax=ax) # 侧边的颜色条带

    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=classes, yticklabels=classes,
           title=None,
           ylabel='Actual',
           xlabel='Predicted')

    # 通过绘制格网，模拟每个单元格的边框
    ax.set_xticks(np.arange(cm.shape[1] + 1) - .5, minor=True)
    ax.set_yticks(np.arange(cm.shape[0] + 1) - .5, minor=True)
    ax.grid(which="minor", color="gray", linestyle='', linewidth=0.2)
    ax.tick_params(which="minor", bottom=False, left=False)

    # 将x轴上的lables旋转45度
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # 标注百分比信息
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            if cm[i, j] >= 0:
                ax.text(j, i, '%.1f' % (cm[i, j] * 100), ha="center", va="center",
                        color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    plt.savefig('plots/%s.png' % str(sub_name), dpi=300, transparent=True, bbox_inches="tight", pad_inches=0)


def draw_observe_window_plots():
    windows = [5, 10, 15, 20, 25, 30, 35, 40]
    # windows = [5, 10, 15, 20]
    int_f1 = [82.02, 85.25, 87.1, 86.4, 87.31, 88.43, 90.19, 90.81]
    att_f1 = [77.49, 80.54, 82.8, 83.78, 86.02, 87.15, 91.48, 92.49]
    act_f1 = [53.56, 57.22, 60.68, 61.13, 63.67, 67.27, 72.51, 73.59]
    # int_f1 = [0.868, 0.889, 0.894, 0.904]
    # att_f1 = [0.757, 0.795, 0.804, 0.810]
    # act_f1 = [0.558, 0.603, 0.652, 0.682]
    plt.figure(dpi=300)
    l1 = plt.plot(windows, int_f1, 'r--', label='Intent')
    l2 = plt.plot(windows, att_f1, 'g--', label='Attitude')
    l3 = plt.plot(windows, act_f1, 'b--', label='Action')
    plt.plot(windows, int_f1, 'ro-', windows, att_f1, 'g+-', windows, act_f1, 'b^-')
    plt.xlabel('Observation Window Size (Frame)')
    plt.ylabel('F1 score (%)')
    ax = plt.gca()
    x_major_locator = plt.MultipleLocator(5)
    ax.xaxis.set_major_locator(x_major_locator)
    plt.legend()
    plt.savefig('plots/observation_window.png', transparent=True, bbox_inches="tight", pad_inches=0)
    plt.show()
    plt.close()


def draw_attention_weight():
    # width, height = 350, 650
    # width, height = 300, 286
    width, height = 500, 316
    heatmap_data = np.zeros((height, width))
    # points = [[175, 80], [190, 66], [166, 66], [207, 76], [149, 75], [246, 148], [108, 150], [283, 243], [74, 244],
    #           [316, 318], [43, 319], [213, 355], [146, 354], [217, 477], [137, 476], [222, 555], [133, 554], [225, 613],
    #           [130, 613], [243, 606], [110, 605], [212, 575], [140, 575]]
    # points = [[17, 60], [18, 95], [22, 130], [30, 165], [43, 197], [65, 226], [91, 250], [119, 270], [152, 275],
    #           [185, 269], [213, 249], [239, 224], [260, 195], [273, 162], [280, 126], [282, 91], [282, 55], [42, 33],
    #           [58, 20], [81, 16], [103, 19], [125, 28], [169, 26], [190, 17], [213, 13], [236, 16], [253, 29],
    #           [147, 53], [147, 76], [148, 100], [148, 123], [123, 139], [135, 143], [148, 148], [162, 143], [175, 138],
    #           [69, 57], [82, 49], [99, 49], [113, 59], [98, 63], [82, 63], [182, 59], [196, 47], [212, 47], [227, 55],
    #           [214, 60], [198, 61], [99, 181], [117, 174], [136, 170], [149, 172], [163, 169], [183, 172], [202, 179],
    #           [184, 199], [166, 208], [150, 210], [136, 209], [117, 201], [107, 182], [136, 181], [149, 182],
    #           [163, 180], [194, 181], [164, 191], [150, 192], [136, 191]]
    points = [[106, 257], [144, 232], [180, 202], [209, 168], [243, 141], [146, 121], [152, 89], [158, 59], [161, 21],
              [115, 119], [115, 80], [115, 42], [116, 5], [85, 127], [74, 91], [66, 57], [57, 23], [56, 146], [40, 126],
              [27, 103], [6, 70], [392, 257], [353, 232], [318, 203], [289, 168], [255, 142], [352, 121], [346, 89],
              [340, 59], [338, 21], [383, 120], [382, 80], [383, 42], [382, 5], [413, 126], [424, 91], [432, 56],
              [440, 22], [442, 145], [458, 127], [471, 103], [491, 70]]
    # edges = [[0, 1], [0, 2], [1, 3], [2, 4],  # Head
    #          [5, 7], [7, 9], [6, 8], [8, 10],  # Body
    #          [5, 6], [11, 12], [5, 11], [6, 12],
    #          [0, 5], [0, 6], [1, 2],
    #          [11, 13], [12, 14], [13, 15], [14, 16],
    #          [15, 21], [21, 19], [21, 17], [16, 22], [22, 20], [22, 18]]
    # edges = [[23, 24], [24, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 30], [30, 31], [31, 32],
    #          [32, 33], [33, 34], [34, 35],
    #          [35, 36], [36, 37], [37, 38], [38, 39], [40, 41], [41, 42], [42, 43], [43, 44], [45, 46],
    #          [46, 47], [47, 48], [48, 49],
    #          [50, 51], [51, 52], [52, 53], [54, 55], [55, 56], [56, 57], [57, 58], [59, 60], [60, 61],
    #          [61, 62], [62, 63], [63, 64],
    #          [65, 66], [66, 67], [67, 68], [68, 69], [69, 70], [71, 72], [72, 73], [73, 74], [74, 75],
    #          [75, 76], [76, 77], [77, 78],
    #          [78, 79], [79, 80], [80, 81], [81, 82], [82, 83], [83, 84], [84, 85], [85, 86], [86, 87],
    #          [87, 88], [88, 89], [89, 90]]
    edges = [[91, 92], [92, 93], [93, 94], [94, 95], [91, 96], [96, 97], [97, 98], [98, 99], [91, 100],
             [100, 101], [101, 102],
             [102, 103], [91, 104], [104, 105], [105, 106], [106, 107], [91, 108], [108, 109], [109, 110],
             [110, 111], [112, 113],
             [113, 114], [114, 115], [115, 116], [112, 117], [117, 118], [118, 119], [119, 120], [112, 121],
             [121, 122], [122, 123],
             [123, 124], [112, 125], [125, 126], [126, 127], [127, 128], [112, 129], [129, 130], [130, 131],
             [131, 132]]
    weights = [0.006647756788879633, 0.006650110241025686, 0.006643069442361593, 0.006457450799643993,
               0.00645549176260829, 0.007423836272209883, 0.007343783974647522, 0.007085991092026234,
               0.006930300034582615, 0.006731671746820211, 0.006626634392887354, 0.007777763064950705,
               0.007721222471445799, 0.007965287193655968, 0.007877742871642113, 0.01594986766576767,
               0.015233145095407963, 0.007980293594300747, 0.007983325980603695, 0.007955314591526985,
               0.007881935685873032, 0.007872793823480606, 0.007859280332922935, 0.0065261321142315865,
               0.006550973746925592, 0.006547409109771252, 0.006548055913299322, 0.006549823097884655,
               0.006551650352776051, 0.0065521677024662495, 0.0065507953986525536, 0.006547186523675919,
               0.006541258655488491, 0.006534384563565254, 0.006528070196509361, 0.006523488089442253,
               0.006521324161440134, 0.006521675270050764, 0.006525773089379072, 0.006501595955342054,
               0.00652149086818099, 0.006542910356074572, 0.006536365952342749, 0.006536954548209906,
               0.006515575107187033, 0.00650678901001811, 0.006528397090733051, 0.006525030825287104,
               0.006528121419250965, 0.006505948957055807, 0.00651764590293169, 0.006547632161527872,
               0.006549769546836615, 0.006521552801132202, 0.006527765654027462, 0.006552614737302065,
               0.006548459175974131, 0.006551073398441076, 0.006524341180920601, 0.006520193535834551,
               0.00654350221157074, 0.006537343841046095, 0.006536929402500391, 0.006542331539094448,
               0.006519155576825142, 0.006505277939140797, 0.006529700011014938, 0.006523951888084412,
               0.006523524411022663, 0.0065286592580378056, 0.006504368502646685, 0.006532544735819101,
               0.006556057836860418, 0.00654885359108448, 0.006544748321175575, 0.006541640963405371,
               0.0065393648110330105, 0.006538025103509426, 0.006538245361298323, 0.006539846770465374,
               0.0065420703031122684, 0.006544158328324556, 0.006545588839799166, 0.0065460046753287315,
               0.006545419339090586, 0.006543748080730438, 0.0065413364209234715, 0.006540296133607626,
               0.00654213409870863, 0.006548793986439705, 0.0065286592580378056, 0.010756929405033588,
               0.008261632174253464, 0.008524593897163868, 0.00888984277844429, 0.008240455761551857,
               0.008393576368689537, 0.008750269189476967, 0.009134974330663681, 0.008370853960514069,
               0.00844859890639782, 0.00883782934397459, 0.009214542806148529, 0.008414301089942455,
               0.008538275957107544, 0.009021067060530186, 0.00946190394461155, 0.00859605148434639,
               0.008556471206247807, 0.00910730380564928, 0.009667719714343548, 0.008791226893663406,
               0.010788199491798878, 0.008327750489115715, 0.008583695627748966, 0.008910986594855785,
               0.008244560100138187, 0.008423622697591782, 0.008727998472750187, 0.009037849493324757,
               0.008276339620351791, 0.008464583195745945, 0.008811184205114841, 0.009155208244919777,
               0.008369824849069118, 0.008494474925100803, 0.008871086873114109, 0.00923588965088129,
               0.008434209041297436, 0.008517364971339703, 0.008946817368268967, 0.009392679668962955,
               0.008580510504543781]
    print(len(weights))
    # weights = weights[:23]
    # weights = weights[23:23 + 68]
    weights = weights[23 + 68:]
    x, y = [], []
    for i, p in enumerate(points):
        x.append(p[0])
        y.append(p[1])
        heatmap_data[p[1], p[0]] = weights[i]
    heatmap_data = cv2.GaussianBlur(heatmap_data, (75, 75), sigmaX=0, sigmaY=0)
    plt.imshow(heatmap_data, cmap='YlOrRd', alpha=0.5)  # Use alpha to make the heatmap semi-transparent
    # plt.colorbar()
    plt.scatter(x, y, marker='.', color='black')
    for e in edges:
        # plt.plot((points[e[0]][0], points[e[1]][0]), (points[e[0]][1], points[e[1]][1]), linewidth=1, color='black')
        # plt.plot((points[e[0] - 23][0], points[e[1] - 23][0]), (points[e[0] - 23][1], points[e[1] - 23][1]),
        #          linewidth=1, color='black')
        plt.plot((points[e[0] - 23 - 68][0], points[e[1] - 23 - 68][0]),
                 (points[e[0] - 23 - 68][1], points[e[1] - 23 - 68][1]),
                 linewidth=1, color='black')
    plt.axis('equal')
    plt.axis('off')
    plt.show()


def draw_pie_chart():
    sizes = [28, 25, 12, 30, 30, 31, 23, 24, 17, 70]
    labels = ['Hand Shake', 'Hug', 'Pet', 'Wave', 'Punch', 'Throw', 'Point-Converse', 'Gaze', 'Leave', 'No Response']
    colors = [(np.random.random(), np.random.random(), np.random.random()) for _ in labels]

    def make_autopct(values):
        def my_autopct(pct):
            total = sum(values)
            val = int(round(pct * total / 100.0))
            # 同时显示数值和占比的饼图
            return '{p:.1f}%  ({v:d})'.format(p=pct, v=val)

        return my_autopct

    plt.pie(sizes, labels=labels, colors=colors, startangle=90, autopct=make_autopct(sizes))
    plt.show()


if __name__ == '__main__':
    draw_observe_window_plots()
    # draw_attention_weight()
    # draw_pie_chart()
